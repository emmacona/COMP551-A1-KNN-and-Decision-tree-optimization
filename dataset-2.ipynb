{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Preprocessing Dataset #2"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Import the data"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "# 1. Load the datasets into Pandas dataframes\n",
    "names2=['A1-Time','A2','A3','A4','A5','A6','A7','A8','A9','LABEL']\n",
    "#Full training set will be split into training and validation\n",
    "dataset2_trn_full = pd.read_csv('shuttle_trn.csv', index_col=False, names=names2, sep=' ', engine='python') \n",
    "dataset2_test = pd.read_csv('shuttle_tst.csv', index_col=False, names=names2, sep=' ', engine='python')\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Data visulization & Cleaning\n",
    "### Note: Data is complete, no missing entries"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Visualizing data to have a better idea of the data\n",
    "# Plotting frequency of different attribute values since there are only 9 (+ 1 for assigned labels)\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import zscore\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "\n",
    "# Visualize all numerical categories\n",
    "dataset2_trn_full.hist(figsize=(20, 14))\n",
    "\n",
    "'''\n",
    "#removing outliers\n",
    "subset=dataset2_trn.loc[:,'A2':'A9']\n",
    "print(subset)\n",
    "z_scores = stats.zscore(subset)\n",
    "abs_z_scores = np.abs(z_scores)\n",
    "filtered_entries = (abs_z_scores < 3).all(axis=1)\n",
    "print(filtered_entries)\n",
    "dataset2_trn = dataset2_trn[filtered_entries]'''\n",
    "\n",
    "print(dataset2_trn_full.describe())\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# Normalizing data since scales of some attributes are drastically different\n",
    "from sklearn import preprocessing\n",
    "\n",
    "x_train2 = dataset2_trn_full.values\n",
    "'''min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x_train)\n",
    "normalized_dataset_2 = pd.DataFrame(x_scaled, columns=names2)\n",
    "\n",
    "normalized_dataset_2.hist(figsize=(20, 14))'''\n",
    "\n",
    "scaler = preprocessing.StandardScaler()\n",
    "\n",
    "# fit the scaler \n",
    "scaler.fit(x_train2)\n",
    "\n",
    "# transform the data\n",
    "x_train_normal = scaler.transform(x_train2)\n",
    "\n",
    "normalized_dataset2 = pd.DataFrame(x_train_normal, columns=names2)\n",
    "\n",
    "normalized_dataset2.hist(figsize=(20, 14))\n",
    "\n",
    "print(normalized_dataset2.describe())\n",
    "\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## One-hot coding\n",
    "### No need for one-hot coding since all attributes and labels are numerical values"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Cross Validation"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Split training data into training and validation, start with 9:1 ratio (90% traning, 10% validation)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "x_d2=normalized_dataset2.loc[:,'A1-Time':'A9']\n",
    "y_d2=normalized_dataset2.loc[:,'LABEL']\n",
    "\n",
    "def splitTraining(p_val,num_instances):\n",
    "    n_val=num_instances//p_val\n",
    "    inds = np.random.permutation(num_instances)\n",
    "    x_val2,y_val2=x_d2.loc[inds[:n_val],:],y_d2.loc[inds[:n_val]]\n",
    "    x_train2,y_train2=x_d2.loc[inds[n_val:],:],y_d2.loc[inds[n_val:]]\n",
    "    \n",
    "    return n_val, x_val2,y_val2, x_train2, y_train2"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Cross validation method"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "def cross_validate(total_nval, n_folds=5):\n",
    "    #get the number of data samples in each split\n",
    "    n_val = total_nval // n_folds\n",
    "    inds = np.random.permutation(total_nval)\n",
    "    inds = []\n",
    "    for f in range(n_folds):\n",
    "        tr_inds = []\n",
    "        #get the validation indexess\n",
    "        val_inds = list(range(f * n_val, (f+1)*n_val))\n",
    "        #get the train indexes\n",
    "        if f > 0:\n",
    "            tr_inds = list(range(f*n_val))\n",
    "        if f < n_folds - 1:\n",
    "            tr_inds = tr_inds + list(range((f+1)*n_val, total_nval))\n",
    "        #The yield statement suspends functionâ€™s execution and sends a value back to the caller\n",
    "        #but retains enough state information to enable function to resume where it is left off\n",
    "        yield tr_inds, val_inds"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# KNN"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "source": [
    "from sklearn import neighbors\n",
    "\n",
    "(trn_instances, num_features) = dataset2_trn_full.shape\n",
    "\n",
    "num_folds = 5\n",
    "\n",
    "K_list=range(1,1000)\n",
    "\n",
    "err_train,err_valid = np.zeros(len(K_list)), np.zeros((len(K_list), num_folds))\n",
    "\n",
    "#split the data\n",
    "(n_val, x_val2,y_val2, x_train2, y_train2)=splitTraining(10,trn_instances)\n",
    "#converting training and validation dataframe sets to numpy arrays\n",
    "x_val2=x_val2.to_numpy\n",
    "y_val2=y_val2.to_numpy\n",
    "x_train2=x_train2.to_numpy\n",
    "y_train2=y_train2.to_numpy\n",
    "\n",
    "print(x_val2.shape)\n",
    "\n",
    "#define a function for the MSE losss\n",
    "loss = lambda y, yh: np.mean((y-yh)**2)\n",
    "'''\n",
    "for i, K in enumerate(K_list):\n",
    "    #Find the validation errors for num_folds splits for a given K\n",
    "    model = neighbors.KNeighborsRegressor(n_neighbors=K)\n",
    "    model = model.fit(x_train2, y_train2)\n",
    "    err_train[i]= loss(y_train2, model.predict(x_train2))\n",
    "    for f, (tr, val) in enumerate(cross_validate(n_val, num_folds)):\n",
    "        model = neighbors.KNeighborsRegressor(n_neighbors=K)\n",
    "        model = model.fit(x_val2[tr,:], y_val2[tr])\n",
    "        err_valid[i, f] = loss(y_val2[val], model.predict(x_val2[val])) \n",
    "   \n",
    "plt.plot(K_list, err_train,  label='test')\n",
    "plt.errorbar(K_list, np.mean(err_valid, axis=1), np.std(err_valid, axis=1), label='validation')\n",
    "plt.legend()\n",
    "plt.xlabel('K (number of neighbours)')\n",
    "plt.ylabel('mean squared error')\n",
    "plt.show()'''"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"\\nfor i, K in enumerate(K_list):\\n    #Find the validation errors for num_folds splits for a given K\\n    model = neighbors.KNeighborsRegressor(n_neighbors=K)\\n    model = model.fit(x_train2, y_train2)\\n    err_train[i]= loss(y_train2, model.predict(x_train2))\\n    for f, (tr, val) in enumerate(cross_validate(n_val, num_folds)):\\n        model = neighbors.KNeighborsRegressor(n_neighbors=K)\\n        model = model.fit(x_val2[tr,:], y_val2[tr])\\n        err_valid[i, f] = loss(y_val2[val], model.predict(x_val2[val])) \\n   \\nplt.plot(K_list, err_train,  label='test')\\nplt.errorbar(K_list, np.mean(err_valid, axis=1), np.std(err_valid, axis=1), label='validation')\\nplt.legend()\\nplt.xlabel('K (number of neighbours)')\\nplt.ylabel('mean squared error')\\nplt.show()\""
      ]
     },
     "metadata": {},
     "execution_count": 143
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}